Istio 权威指南



### 服务治理

微服务的服务治理指的是服务注册、服务发现、负载均衡、熔断和调用链追踪等。这些主要是解决单体转微服务过程中带来的问题。

#### 服务治理的形态

##### 第一种形态：治理逻辑和业务代码耦合

需要开发者写代码实现服务注册、服务发现、负载均衡等逻辑，这会导致代码中存在大量的重复代码且随着治理逻辑的升级需要协同升级。

##### 第二种形态：治理逻辑和业务代码解耦

把治理逻辑抽象成一个公共库，让所有微服务通过这个公共库来自然获得治理能力（典型例子就是 Spring Cloud）。这种模式虽然解耦了治理逻辑和业务代码，但是实际上治理逻辑还是会与业务代码一起发布，且当治理逻辑发生变动时也需要重新编译以及部署业务代码，会给生产带来额外的风险。

##### 第三种形态：治理逻辑与业务进程解耦

将治理逻辑彻底从用户的业务进程中剥离出来（也就是 sidecar 模式）。治理逻辑与业务代码都以独立的进程存在，业务与治理也可以独立进行升级，对应用的侵入也最小。这种模式也就是所谓的**服务网格**形态。

#### Istio 所解决的问题

微服务架构只是一种架构风格，是一种敏捷的软件工程实践。而 Istio 是用来解决应用访问中各种实际问题的，**并不只是微服务模式的另一种落地形式**。

> 通俗的理解，就算不是微服务架构的软件，也可以使用 Istio。

#### 服务网格

William Moran关于服务网格（S ervice Mesh）的定义：

* 基础设施：服务网格是一种处理服务间通信的基础设施层
* 云原生：服务网格尤其适用于在云原生场景中帮助应用程序在复杂的服务拓扑间可靠地传递请求
* 网络代理：在实际应用中，服务网格一般通过一组轻量级网络代理执行治理逻辑
* 对应用透明：虽然轻量级网络代理会和应用程序部署在一起，但应用感知不到代理的存在，仍通过原本的方式工作

云原生时代，服务量剧增，应用间的拓扑也更加复杂，治理需求也越来越强烈。迫切的需要一种具备云原生的动态、弹性特点的应用治理基础设施。

##### Sidecar

Sidecar 与应用的解耦带来的完全无侵入、开发语言无关的特点极大地降低了应用开发者的开发成本。另外作为透明代理，Sidecar 不影响原本的业务访问模式，透明代理会拦截应用程序的所有 Inbound 和 Outbound 流量并对服务运行时进行更高级的控制，使服务可监控、可管理。

Sidecar 是服务网格动作的执行体，全局的管理规则和服务网格内的元数据维护通过一个统一的控制面进行。应用程序感知不到透明代理，也就不会和控制面存在任何联系。

但是 Sidecar 模式在访问链路中多引入的两跳也是不容回避的问题。这会导致两处额外的延迟（可通过基于 **eBPF** 提升流量拦截的效率）和可能的故障点，这也为系统的访问性能、整体可靠性及系统的复杂度都带来了新的挑战。

##### Envoy

Istio 配套的数据面 Envoy 已经是当前服务网格数据面的标准实现，其控制面的 xDS 协议也已经成为服务网格数据面的事实标准协议。Envoy 满足服务网格对透明代理轻量、高性能的要求，提供 L3/L4 过滤器、HTTP L7 过滤器，支持 HTTP、gRPC、TCP、TLS、MySQL、Redis 等多种协议。

#### Kubernetes

Kubernetes 虽然已经通过 Service 机制提供了服务注册、服务发现以及负载均衡问题，通过 Readiness 健康检查实现了一定程度的故障隔离和恢复功能。但是 Kubernetes 提供的这些能力大都停留在 L4 的互访上，对于服务化要求较高的用户，如果需要实现熔断、限流、动态路由或者调用埋点等应用层的能力，仍然需要使用服务网格来提供可观测性、服务韧性、灵活分流、弹性、安全等能力。

Istio 正是在 Kubernetes 之上叠加了一层面向应用、感知应用的服务管理平台和基础设施，提供了强大的可扩展的非侵入式的七层流量管理能力。

##### Istio 的管理

Istio 在管理 Kubernetes 流量时，复用了 Kubernetes 中 Service 的定义，它的服务发现是从 Kube-Apiserver 中获取 Service 和 Endpoints，然后将其转换为 Istio 的服务模型。但是其数据面组件不再是 kube-proxy，而是在每个 Pod 中部署的 sidecar 容器，也可以将其看作每个服务实例的 Proxy。

当发生服务间访问时，Istio 数据面透明地拦截 Pod 的 Inbound 流量和 Outbound 流量，接管服务间访问的流量。服务网格数据面代理识别和解析各种应用层协议，根据控制面上该服务对应协议的配置执行丰富的流量管理动作。

基于 sidecar 的服务网格透明代理代替了 Kubernetes 中的 kube-proxy 拦截和处理东西流量。对于入口的南北流量，Istio 也有基于 Envoy 建立的 ingress-gateway。

##### Istio 如何发挥作用

Istio 最大化利用了 Kubernetes 这个基础设施，主要体现在以下方面：

* **基于 Kubernetes Pod 的服务网格数据面管理**：基于 Kubernetes 一个 Pod 多个容器的优秀设计使得部署运维对用户透明。用户还是用原本的方式创建负载，通过 Istio 的自动注入机制，在业务 Pod 创建时自动给指定的负载注入代理容器。
* **基于 Kubernetes 机制的透明流量拦截**：早期基于 init container 机制，在业务容器启动前执行 iptables 规则，将业务容器的出入流量拦截到数据面代理上。新版本基于 Kubernetes CNI 机制，在 Pod 创建或销毁时执行服务网格拦截流量的规则，将业务流量转发到服务网格数据面代理上。
* **基于 Kubernetes Service 的服务发现**：Istio 的服务发现机制完美地基于 Kubernetes 的域名访问机制构建而成。
* **基于 Kubernetes 的控制面组件管理**：Istio 的控制面组件是以容器形式部署在 Kubernetes 集群中，这些 Kubernetes 原生或扩展的能力，大大方便了服务网格组件自身的运维。

### Istio 的架构

Istio 在架构上分为控制面和数据面两部分，**控制面只有一个单体应用 istiod**，**数据面主要由伴随每个业务程序部署的代理 Envoy 组成**，Envoy 根据控制面的配置执行流量管理操作。

#### 服务模型

服务、服务版本、服务实例等对象构成了 Istio 的服务模型。在 Kubernetes 场景中，Istio 的服务模型基于 Kubernetes 的 Service、Endpoints 资源对象构建而成，并加上部分约束来满足 Istio 服务模型的要求。

* 端口命名格式：**规范格式是 `<protocol>[-suffix]`** ，其中 `protocol` 可以是 `tcp, http, grpc, mysql, redis` 等。Istio 根据端口名获取应用协议的类型，进而提供对应的流量治理能力。在 `k8s 1.18` 之后的版本可以通过 `appProtocol` 配置服务的应用协议。
* 服务关联：**一个服务相关联的 Pod 在同一个端口上最好是相同的协议**，否则 Envy 监听器可能会出现意料之外的错误。
* 应用的 Deployment 使用 app 和 version 标签。基于 app 和 version 标签构建的可观测性元数据信息可以对可观测性进行各种维度的管理，version 标签还可用于灰度发布中对灰度版本进行标识。

#### 服务 Service

服务是服务网格 Istio 管理的主要资源对象。在 Kubernetes 场景中，满足 Istio 规范约束的服务比较简单，**唯一需要做的就是在端口名称上指定协议类型**。

#### 服务版本 Version

在 Istio 中，灰度发布是一个重要的场景，要求一个服务有多个不同的版本的实现。在 Kubernetes 中对多个版本的定义是**将一个服务关联到多个 Deployment，每个 Deployment 都对应服务的一个版本**（通过 app 和 version 标签）。

#### 服务实例 Instance

服务实例是真正处理服务请求的后端。在 Kubernetes 场景中对应的是 Endpoints 资源。Istio 对虚拟机和其他形态的服务和负载也提供一套更通用的服务模型，在虚拟机场景中，Istio 提供了 `ServiceEntry`、`WorkloadEntry`、`WorkloadGroup` 等对象来描述。

### 主要组件

控制面组件原本使用的微服务模式，有 `Pilot`、`Galley`、`Citadel` 和 `Mixer` 组成，出于简化安装复杂度、配置复杂度和简化控制面维护等原因，将其重构为一个单体应用 istiod。在 istio 内部，依然在使用组件化进行维护

#### Pilot

Pilot 是 istio 的控制中枢，用于下发指令控制 Envoy 完成一系列功能。Pilot 主要包含两部分工作：服务发现和配置管理。除了服务发现之外，Pilot 更重要的功能是构造维护和向数据面下发规则，包括 `VirtualService`、`DestinationRule`、`Gateway` 等流量规则，也包括 `RequestAuthentication`、`PeerAuthentication` 等安全规则。

#### Citadel

Citadel 是 Istio 的核心安全组件，提供了自动生成、分发、轮换与撤销密钥和证书的功能。

#### Galley

Galley 是服务网格控制面负责配置管理的组件，其作为 Webhook Server 也承担了 Kubernetes 的准入控制器，在创建资源对象时对其进行校验、拦截等操作。同时 Galley 还负责监控各种 API 资源对象，在资源发生变化时，通知 Pilot 根据最新的对象生成 xDS 配置，并推送给相关的数据面 sidecar。

### 数据面组件

数据面组件一般特指数据面代理 Istio-proxy，这不是通用的 Envoy，而是叠加了 Istio 的 Proxy 功能的一个扩展版本，包括可观测性元数据的交换，指标生成等

#### Ambient

Istio 在 2022 年 9 月推出了另一种共享代理的数据面模式 Ambient，**在不使用传统 sidecar 的情况下，保持零信任安全、流量管理和可观测性等核心功能**。但相比 sidecar 模式，其业务侵入性更低，升级管理更简单。

Ambient 代理模型包含两个组件：ztunnel 和 waypoint。ztunnel 以 Daemonset 部署在每个节点上，为服务网格中的应用提供 mTLS、可观测性、身份验证和四层授权等功能。waypoint 则专注于七层治理的能力，包括 HTTP 路由、负载均衡、熔断、重试等流量管理功能以及七层授权。

### Istio 的实现

#### 流量拦截

**Istio 默认通过注入 init 容器进行 iptables 规则的设置**，拦截进入容器的 Inbound 流量和从应用程序发出的 Outbound 流量。这种方案实现简单，但是**需要 `NET_ADMIN` 和 `NET_RAW` 权限执行网络设置**。而使用 **Istio CNI 插件可以取代 Init 容器进行流量拦截规则的设置**，插件通过识别用户应用程序 Pod 和需要流量重定向的 sidecar，并**在 Kubernetes Pod 生命周期的网络设置阶段进行设置**，从而消除用户在启用 Istio 的集群中对 Pod 额外的权限要求。

#### 服务发现

服务发起方的 Envoy 调用 Istiod 的服务发现接口获取目标服务的实例列表，为负载均衡做准备。

##### 负载均衡

服务发起方的 Envoy 根据配置的负载均衡策略选择服务实例，并将请求分发到对应的目标服务实例上。

#### 流量治理

Envoy 从 Istiod 中获取配置的流量治理规则，在拦截到 Inbound 流量和 Outbound 流量时执行治理逻辑。

#### 访问安全

在服务间访问时，Envoy 可以进行双向认证和通道加密，并基于授权策略的配置对请求进行鉴权。

#### 服务监控

在服务通信时，通信双方的 Envoy 根据请求的信息进行监控指标的统计、访问日志的收集和分布式调用链的埋点等。

### 流量治理的原理

